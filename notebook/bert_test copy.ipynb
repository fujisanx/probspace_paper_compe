{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import collections\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               id                     submitter  \\\n",
       "0  hep-ph/9902295               Michael Kraemer   \n",
       "1       1403.7138                      Aigen Li   \n",
       "2       1405.5857             Michael Mortonson   \n",
       "3      1807.01034  Evangelos Thomas Karamatskos   \n",
       "4      1905.05921                   Juanjuan Gu   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Mark E. Hayes (University College London) and ...   \n",
       "1  Qi Li, S.L. Liang, Aigen Li (University of Mis...   \n",
       "2              Michael J. Mortonson, Uro\\v{s} Seljak   \n",
       "3  Evangelos T. Karamatskos, Sebastian Raabe, Ter...   \n",
       "4                           Juanjuan Gu and Yun Jing   \n",
       "\n",
       "                                               title  \\\n",
       "0                   Heavy-Flavour Production at HERA   \n",
       "1  Spectropolarimetric Constraints on the Nature ...   \n",
       "2  A joint analysis of Planck and BICEP2 B modes ...   \n",
       "3  Molecular movie of ultrafast coherent rotation...   \n",
       "4  A Modified Mixed Domain Method for Modeling Ac...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  LaTeX, 21 pages, 13 Postscript figures. Summar...   \n",
       "1  5 pages, 2 figures; accepted for publication i...   \n",
       "2  13 pages, 4 figures; submitted to JCAP; refere...   \n",
       "3                                          9 Figures   \n",
       "4                                               None   \n",
       "\n",
       "                  journal-ref                            doi  \\\n",
       "0   J.Phys.G25:1477-1493,1999     10.1088/0954-3899/25/7/332   \n",
       "1                        None          10.1093/mnrasl/slu021   \n",
       "2             JCAP10(2014)035  10.1088/1475-7516/2014/10/035   \n",
       "3  Nat Commun 10, 3364 (2019)     10.1038/s41467-019-11122-y   \n",
       "4                        None             10.1121/10.0001454   \n",
       "\n",
       "                      report-no                                categories  \\\n",
       "0  CERN-TH/99-30, UCL/HEP 99-03                             hep-ph hep-ex   \n",
       "1                          None                               astro-ph.GA   \n",
       "2                          None           astro-ph.CO gr-qc hep-ph hep-th   \n",
       "3                          None  physics.chem-ph physics.atom-ph quant-ph   \n",
       "4                          None            physics.med-ph physics.comp-ph   \n",
       "\n",
       "                                             license  \\\n",
       "0                                               None   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "3  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "4  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    We review the theoretical and experimental s...   \n",
       "1    While it is well recognized that interstella...   \n",
       "2    We analyze BICEP2 and Planck data using a mo...   \n",
       "3    Recording molecular movies on ultrafast time...   \n",
       "4    In this paper, phase correction and amplitud...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Wed, 10 Feb 199...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Thu, 27 Mar 201...  2015-06-19   \n",
       "2  [{'version': 'v1', 'created': 'Thu, 22 May 201...  2014-10-17   \n",
       "3  [{'version': 'v1', 'created': 'Tue, 3 Jul 2018...  2020-05-19   \n",
       "4  [{'version': 'v1', 'created': 'Wed, 15 May 201...  2020-07-15   \n",
       "\n",
       "                                      authors_parsed doi_cites  cites  \n",
       "0  [[Hayes, Mark E., , University College London]...         1    NaN  \n",
       "1  [[Li, Qi, , University of Missouri], [Liang, S...         8    7.0  \n",
       "2      [[Mortonson, Michael J., ], [Seljak, Uroš, ]]       122  188.0  \n",
       "3  [[Karamatskos, Evangelos T., ], [Raabe, Sebast...         6    8.0  \n",
       "4                  [[Gu, Juanjuan, ], [Jing, Yun, ]]         0    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>submitter</th>\n      <th>authors</th>\n      <th>title</th>\n      <th>comments</th>\n      <th>journal-ref</th>\n      <th>doi</th>\n      <th>report-no</th>\n      <th>categories</th>\n      <th>license</th>\n      <th>abstract</th>\n      <th>versions</th>\n      <th>update_date</th>\n      <th>authors_parsed</th>\n      <th>doi_cites</th>\n      <th>cites</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hep-ph/9902295</td>\n      <td>Michael Kraemer</td>\n      <td>Mark E. Hayes (University College London) and ...</td>\n      <td>Heavy-Flavour Production at HERA</td>\n      <td>LaTeX, 21 pages, 13 Postscript figures. Summar...</td>\n      <td>J.Phys.G25:1477-1493,1999</td>\n      <td>10.1088/0954-3899/25/7/332</td>\n      <td>CERN-TH/99-30, UCL/HEP 99-03</td>\n      <td>hep-ph hep-ex</td>\n      <td>None</td>\n      <td>We review the theoretical and experimental s...</td>\n      <td>[{'version': 'v1', 'created': 'Wed, 10 Feb 199...</td>\n      <td>2008-11-26</td>\n      <td>[[Hayes, Mark E., , University College London]...</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1403.7138</td>\n      <td>Aigen Li</td>\n      <td>Qi Li, S.L. Liang, Aigen Li (University of Mis...</td>\n      <td>Spectropolarimetric Constraints on the Nature ...</td>\n      <td>5 pages, 2 figures; accepted for publication i...</td>\n      <td>None</td>\n      <td>10.1093/mnrasl/slu021</td>\n      <td>None</td>\n      <td>astro-ph.GA</td>\n      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n      <td>While it is well recognized that interstella...</td>\n      <td>[{'version': 'v1', 'created': 'Thu, 27 Mar 201...</td>\n      <td>2015-06-19</td>\n      <td>[[Li, Qi, , University of Missouri], [Liang, S...</td>\n      <td>8</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1405.5857</td>\n      <td>Michael Mortonson</td>\n      <td>Michael J. Mortonson, Uro\\v{s} Seljak</td>\n      <td>A joint analysis of Planck and BICEP2 B modes ...</td>\n      <td>13 pages, 4 figures; submitted to JCAP; refere...</td>\n      <td>JCAP10(2014)035</td>\n      <td>10.1088/1475-7516/2014/10/035</td>\n      <td>None</td>\n      <td>astro-ph.CO gr-qc hep-ph hep-th</td>\n      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n      <td>We analyze BICEP2 and Planck data using a mo...</td>\n      <td>[{'version': 'v1', 'created': 'Thu, 22 May 201...</td>\n      <td>2014-10-17</td>\n      <td>[[Mortonson, Michael J., ], [Seljak, Uroš, ]]</td>\n      <td>122</td>\n      <td>188.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1807.01034</td>\n      <td>Evangelos Thomas Karamatskos</td>\n      <td>Evangelos T. Karamatskos, Sebastian Raabe, Ter...</td>\n      <td>Molecular movie of ultrafast coherent rotation...</td>\n      <td>9 Figures</td>\n      <td>Nat Commun 10, 3364 (2019)</td>\n      <td>10.1038/s41467-019-11122-y</td>\n      <td>None</td>\n      <td>physics.chem-ph physics.atom-ph quant-ph</td>\n      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n      <td>Recording molecular movies on ultrafast time...</td>\n      <td>[{'version': 'v1', 'created': 'Tue, 3 Jul 2018...</td>\n      <td>2020-05-19</td>\n      <td>[[Karamatskos, Evangelos T., ], [Raabe, Sebast...</td>\n      <td>6</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1905.05921</td>\n      <td>Juanjuan Gu</td>\n      <td>Juanjuan Gu and Yun Jing</td>\n      <td>A Modified Mixed Domain Method for Modeling Ac...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>10.1121/10.0001454</td>\n      <td>None</td>\n      <td>physics.med-ph physics.comp-ph</td>\n      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n      <td>In this paper, phase correction and amplitud...</td>\n      <td>[{'version': 'v1', 'created': 'Wed, 15 May 201...</td>\n      <td>2020-07-15</td>\n      <td>[[Gu, Juanjuan, ], [Jing, Yun, ]]</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_train = pd.read_pickle('../data/train/raw.pickle')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(851524, 16)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  id                                               text  \\\n",
       "0     hep-ph/9902295  Heavy-Flavour Production at HERA  We review th...   \n",
       "4         1905.05921  A Modified Mixed Domain Method for Modeling Ac...   \n",
       "5         1812.07485  Gaussian asymptotic limits for the $\\alpha$-tr...   \n",
       "9         2005.02493  A Framework for Designing and Evaluating Solar...   \n",
       "14  astro-ph/0503092  On the deficit of calculated muon flux at sea ...   \n",
       "\n",
       "   doi_cites  \n",
       "0          1  \n",
       "4          0  \n",
       "5          0  \n",
       "9          0  \n",
       "14         0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>doi_cites</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hep-ph/9902295</td>\n      <td>Heavy-Flavour Production at HERA  We review th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1905.05921</td>\n      <td>A Modified Mixed Domain Method for Modeling Ac...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1812.07485</td>\n      <td>Gaussian asymptotic limits for the $\\alpha$-tr...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2005.02493</td>\n      <td>A Framework for Designing and Evaluating Solar...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>astro-ph/0503092</td>\n      <td>On the deficit of calculated muon flux at sea ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_train = df_train[df_train['cites'].isnull()][['id', 'title', 'abstract', 'doi_cites']]\n",
    "df_train['text'] = df_train['title'] + df_train['abstract']\n",
    "df_train = df_train[['id', 'text', 'doi_cites']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((501843,), (167282,), (167282,))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train['text'].values, df_train['doi_cites'].values, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['hello', 'world']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(tokenizer.tokenize('hello world'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xlnet(mname):\n",
    "    \"\"\" Creates the model. It is composed of the XLNet main block and then\n",
    "    a classification head its added\n",
    "    \"\"\"\n",
    "    # Define token ids as inputs\n",
    "    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n",
    "\n",
    "    # Call XLNet model\n",
    "    xlnet = TFXLNetModel.from_pretrained(mname)\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "\n",
    "    # CLASSIFICATION HEAD \n",
    "    # Collect last step from last hidden state (CLS)\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    # Apply dropout for regularization\n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "    # Final output \n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "\n",
    "    # Compile model\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='mse', metrics=['mes', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model\n",
    "#xlnet = create_xlnet(xlnet_model)\n",
    "#xlnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(texts, tokenizer):\n",
    "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
    "    max_length = 172\n",
    "    shape = (len(texts), max_length)\n",
    "    input_ids = np.zeros(shape, dtype=\"int32\")\n",
    "    attention_mask = np.zeros(shape, dtype=\"int32\")\n",
    "    token_type_ids = np.zeros(shape, dtype=\"int32\")\n",
    "    for i, text in enumerate(texts):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        encoded_dict = tokenizer.encode_plus(text, max_length=max_length, pad_to_max_length=True)\n",
    "        input_ids[i] = encoded_dict[\"input_ids\"]\n",
    "        attention_mask[i] = encoded_dict[\"attention_mask\"]\n",
    "        token_type_ids[i] = encoded_dict[\"token_type_ids\"]\n",
    "    return [input_ids, attention_mask, token_type_ids]\n",
    "\n",
    "def warmup(epoch, lr):\n",
    "    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n",
    "    However, as we are finetuning for few epoch it's not crucial.\n",
    "    \"\"\"\n",
    "    return max(lr +1e-6, 2e-5)\n",
    "\n",
    "def plot_metrics(pred, true_labels):\n",
    "    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n",
    "    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
    "    auc = roc_auc_score(true_labels, pred)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='red')\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n",
    "    return fig\n",
    "#inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model(transformer, num_cls=1, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(num_cls, activation='softmax')(cls_token)\n",
    "\n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=2e-4), loss='categorical_crossentropy', metrics=['accuracy']) # lr = 5e-5 * 4\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2fa22df8e351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "def encode_texts(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        list(texts), \n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    return np.array(enc_di['input_ids'], dtype = 'int32')\n",
    "\n",
    "x_train = encode_texts(X_train, tokenizer)\n",
    "x_valid = encode_texts(X_valid, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|            Variable Name|    Memory|\n ------------------------------------ \n|            AutoTokenizer|      1064|\n|                       In|       264|\n|                      Out|       360|\n|                     Path|       896|\n|             TFXLNetModel|      1064|\n|           XLNetTokenizer|      1064|\n|                   X_test|   1338352|\n|                  X_train|   4014840|\n|                    X_val|   1338352|\n|           accuracy_score|       136|\n|              collections|        72|\n|             create_xlnet|       136|\n|                 df_train|1008368901|\n|             encode_texts|       136|\n|                     exit|        48|\n|               get_inputs|       136|\n|              get_ipython|        64|\n|                     nltk|        72|\n|                       np|        72|\n|                       os|        72|\n|                       pd|        72|\n|             plot_metrics|       136|\n|                      plt|        72|\n|                     quit|        48|\n|                       re|        72|\n|            roc_auc_score|       136|\n|                roc_curve|       136|\n|                      sns|        72|\n|                      sys|        72|\n|                       tf|        72|\n|                tokenizer|        48|\n|         train_test_split|       136|\n|             transformers|        72|\n|                 var_name|        57|\n|                   warmup|       136|\n|                   x_test| 342593648|\n|                  x_train|1027774576|\n|                   y_test|   1338352|\n|                  y_train|   4014840|\n|                    y_val|   1338352|\n"
     ]
    }
   ],
   "source": [
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.027774576"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "1027774576 / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|            Variable Name|    Memory|\n ------------------------------------ \n|            AutoTokenizer|      1064|\n|                       In|       192|\n|                      Out|       360|\n|                     Path|       896|\n|             TFXLNetModel|      1064|\n|           XLNetTokenizer|      1064|\n|                   X_test|   1338352|\n|                  X_train|   4014840|\n|                    X_val|   1338352|\n|           accuracy_score|       136|\n|              collections|        72|\n|             create_xlnet|       136|\n|                 df_train|1008368901|\n|             encode_texts|       136|\n|                     exit|        48|\n|               get_inputs|       136|\n|              get_ipython|        64|\n|                     nltk|        72|\n|                       np|        72|\n|                       os|        72|\n|                       pd|        72|\n|             plot_metrics|       136|\n|                      plt|        72|\n|                     quit|        48|\n|                       re|        72|\n|            roc_auc_score|       136|\n|                roc_curve|       136|\n|                      sns|        72|\n|                      sys|        72|\n|                       tf|        72|\n|                tokenizer|        48|\n|         train_test_split|       136|\n|             transformers|        72|\n|                 var_name|        57|\n|                   warmup|       136|\n|                   x_test| 685187184|\n|                   y_test|   1338352|\n|                  y_train|   4014840|\n|                    y_val|   1338352|\n"
     ]
    }
   ],
   "source": [
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=4, min_delta=0.02, restore_best_weights=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mse', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = xlnet.fit(x=inp_tok, y=y_train, epochs=15, batch_size=16, validation_split=.15, callbacks=callbacks)"
   ]
  }
 ]
}